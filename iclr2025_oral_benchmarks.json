[
  {
    "url": "http://arxiv.org/abs/2410.09114",
    "paper_url": "https://openreview.net/pdf?id=odjMSBSWRt",
    "paper_id": "odjMSBSWRt",
    "contexts": [
      "trophic cyber capabilities benchmark (3cb): Robustly evaluating llm agent cyber offensecapabilities."
    ]
  },
  {
    "url": "http://arxiv.org/abs/2410.09247",
    "paper_url": "https://openreview.net/pdf?id=odjMSBSWRt",
    "paper_id": "odjMSBSWRt",
    "contexts": [
      "and Jason Schreiber. 2024. Benchmark inflation: Revealing llm performance gaps usingretro-holdouts."
    ]
  },
  {
    "url": "http://arxiv.org/abs/2411.08813",
    "paper_url": "https://openreview.net/pdf?id=odjMSBSWRt",
    "paper_id": "odjMSBSWRt",
    "contexts": [
      "thinking cyberseceval: An llm-aided approach to evaluation critique."
    ]
  },
  {
    "url": "http://arxiv.org/abs/2403.03218",
    "paper_url": "https://openreview.net/pdf?id=odjMSBSWRt",
    "paper_id": "odjMSBSWRt",
    "contexts": [
      "Isabelle Barrass, Oliver Zhang, Xiaoyuan Zhu, Rishub Tamirisa, Bhrugu Bharathi, AdamKhoja, Zhenqi Zhao, Ariel Herbert-Voss, Cort B. Breuer, Samuel Marks, Oam Patel,Andy Zou, Mantas Mazeika, Zifan Wang, Palash Oswal, Weiran Liu, Adam A. Hunt,Justin Tienken-Harder, Kevin Y. Shih, Kemper Talley, John Guan, Russell Kaplan, IanSteneker, David Campbell, Brad Jokubaitis, Alex Levinson, Jean Wang, William Qian,Kallol Krishna Karmakar, Steven Basart, Stephen Fitz, Mindy Levine, Ponnurangam Ku-maraguru, Uday Tupakula, Vijay Varadharajan, Yan Shoshitaishvili, Jimmy Ba, Kevin M.Esvelt, Alexandr Wang, and Dan Hendrycks. 2024. The wmdp benchmark: Measuringand reducing malicious use with unlearning."
    ]
  },
  {
    "url": "https://aclanthology.org/2024.lrec-main.884",
    "paper_url": "https://openreview.net/pdf?id=odjMSBSWRt",
    "paper_id": "odjMSBSWRt",
    "contexts": [
      "Matthias Spielkamp, and Birgit Stark. 2024. Large language models are echo chambers.In Proceedings of the 2024 Joint International Conference on Computational Linguistics,Language Resources and Evaluation (LREC-COLING 2024), pages 10117–10123, Torino,Italia. ELRA and ICCL."
    ]
  },
  {
    "url": "http://arxiv.org/abs/2304.03279",
    "paper_url": "https://openreview.net/pdf?id=odjMSBSWRt",
    "paper_id": "odjMSBSWRt",
    "contexts": [
      "side, Jonathan Ng, Hanlin Zhang, Scott Emmons, and Dan Hendrycks. 2023. Do therewards justify the means? measuring trade-offs between rewards and ethical behavior inthe machiavelli benchmark."
    ]
  },
  {
    "url": "http://arxiv.org/abs/2404.03189",
    "paper_url": "https://openreview.net/pdf?id=odjMSBSWRt",
    "paper_id": "odjMSBSWRt",
    "contexts": [
      "probabilities also matter: A more faithful metric for faithfulness of free-text explanationsin large language models."
    ]
  },
  {
    "url": "https://github.com/THU-KEG/RM-Bench",
    "paper_url": "https://openreview.net/pdf?id=QEHrmQPBdd",
    "paper_id": "QEHrmQPBdd",
    "contexts": [
      "Reward models are critical in techniques like Reinforcement Learning from Hu-man Feedback (RLHF) and Inference Scaling Laws, where they guide languagemodel alignment and select optimal responses. Despite their importance, existingreward model benchmarks often evaluate models by asking them to distinguish be-tween responses generated by models of varying power. However, this approachfails to assess reward models on subtle but critical content changes and variationsin style, resulting in a low correlation with policy model performance. To thisend, we introduce RM-BENCH, a novel benchmark designed to evaluate rewardmodels based on their sensitivity to subtle content differences and resistance tostyle biases. Extensive experiments demonstrate that RM-BENCH strongly corre-lates with policy model performance, making it a reliable reference for selectingreward models to align language models effectively. We evaluate nearly 40 re-ward models on RM-BENCH. Our results reveal that even state-of-the-art modelsachieve an average performance of only 46.6%, which falls short of random-levelaccuracy (50%) when faced with style bias interference. These findings highlightthe significant room for improvement in current reward models. Related code anddata are available at https://github.com/THU-KEG/RM-Bench."
    ]
  },
  {
    "url": "https://huggingface.co/datasets/HuggingFaceH4/stack-exchange-preferences",
    "paper_url": "https://openreview.net/pdf?id=QEHrmQPBdd",
    "paper_id": "QEHrmQPBdd",
    "contexts": [
      "stack exchange preference dataset, 2023. URL https://huggingface.co/datasets/HuggingFaceH4/stack-exchange-preferences",
      "."
    ]
  },
  {
    "url": "https://linkinghub.elsevier.com/retrieve/pii/S089662732030605X",
    "paper_url": "https://openreview.net/pdf?id=aWXnKanInf",
    "paper_id": "aWXnKanInf",
    "contexts": [
      "James J. DiCarlo. Integrative Benchmarking to Advance Neurally Mechanistic Models of Hu-man Intelligence. Neuron, 108(3):413–423, November 2020. ISSN 08966273. doi: 10.1016/j.neuron.2020.07.040. URL https://linkinghub.elsevier.com/retrieve/pii/S089662732030605X"
    ]
  },
  {
    "url": "https://doi.org/10.48550/arXiv.2306.14898",
    "paper_url": "https://openreview.net/pdf?id=XmProj9cPs",
    "paper_id": "XmProj9cPs",
    "contexts": [
      "and benchmarking interactive coding with execution feedback. CoRR, abs/2306.14898, 2023. doi:10.48550/arXiv.2306.14898. URL https://doi.org/10.48550/arXiv.2306.14898."
    ]
  },
  {
    "url": "https://github.com/allenai/OLMo/tree/main",
    "paper_url": "https://openreview.net/pdf?id=eHehzSDUFp",
    "paper_id": "eHehzSDUFp",
    "contexts": [
      "5We used OLMo and Dolma from the official repository"
    ]
  },
  {
    "url": "https://huggingface.co/datasets/ncbi/pubmed",
    "paper_url": "https://openreview.net/pdf?id=eHehzSDUFp",
    "paper_id": "eHehzSDUFp",
    "contexts": [
      "7We randomly sample 205k instances for each dataset.8Datasets in huggingface9We slightly modified the dataset to our setting of which details are in Appendix B.1"
    ]
  },
  {
    "url": "https://api.semanticscholar.org/CorpusID:227231454",
    "paper_url": "https://openreview.net/pdf?id=eHehzSDUFp",
    "paper_id": "eHehzSDUFp",
    "contexts": [
      "ral language processing: A survey. ArXiv, abs/2012.09823, 2020. URL https://api.semanticscholar.org/CorpusID:227231454",
      "."
    ]
  },
  {
    "url": "https://api.semanticscholar.org/CorpusID:251223709",
    "paper_url": "https://openreview.net/pdf?id=eHehzSDUFp",
    "paper_id": "eHehzSDUFp",
    "contexts": [
      "bank for pretrained transformers. In Natural Language Processing and Chinese Computing, 2022b. URLhttps://api.semanticscholar.org/CorpusID:251223709",
      "."
    ]
  },
  {
    "url": "https://api.semanticscholar.org/CorpusID:259251905",
    "paper_url": "https://openreview.net/pdf?id=eHehzSDUFp",
    "paper_id": "eHehzSDUFp",
    "contexts": [
      "and Richard S. Sutton. Loss of plasticity in deep continual learning. Nature, 632:768 – 774, 2024. URLhttps://api.semanticscholar.org/CorpusID:259251905",
      "."
    ]
  },
  {
    "url": "https://api.semanticscholar.org/CorpusID:202539551",
    "paper_url": "https://openreview.net/pdf?id=eHehzSDUFp",
    "paper_id": "eHehzSDUFp",
    "contexts": [
      ", 2019. URL https://api.semanticscholar.org/CorpusID:202539551."
    ]
  },
  {
    "url": "https://api.semanticscholar.org/CorpusID:270068372",
    "paper_url": "https://openreview.net/pdf?id=eHehzSDUFp",
    "paper_id": "eHehzSDUFp",
    "contexts": [
      "circuits in pretrained transformers. ArXiv, abs/2405.17969, 2024. URL https://api.semanticscholar.org/CorpusID:270068372",
      "."
    ]
  }
]